{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Processing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import random\n",
    "\n",
    "# Count vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transcript</th>\n",
       "      <th>PHQ_Score</th>\n",
       "      <th>PHQ_Binary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>good atlanta georgia um my parents um i love i...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>thank you mmm k i good thank you i los angeles...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>i fine yourself i los angeles california part ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>okay bout yourself california yeah oh well it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>i good um los angeles california um cool weath...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Transcript  PHQ_Score  \\\n",
       "Participant_ID                                                                 \n",
       "300             good atlanta georgia um my parents um i love i...          2   \n",
       "301             thank you mmm k i good thank you i los angeles...          3   \n",
       "302             i fine yourself i los angeles california part ...          4   \n",
       "303             okay bout yourself california yeah oh well it ...          0   \n",
       "304             i good um los angeles california um cool weath...          6   \n",
       "\n",
       "                PHQ_Binary  \n",
       "Participant_ID              \n",
       "300                      0  \n",
       "301                      0  \n",
       "302                      0  \n",
       "303                      0  \n",
       "304                      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"clean_compiled_transcripts.csv\", index_col = \"Participant_ID\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert transcripts to occurrence matrix (skip if you have the numpy data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = CountVectorizer(min_df=3) # ignore terms that appear in less than 3 documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset (skip if you have the numpy data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = CV.fit_transform(df.Transcript).toarray()\n",
    "y = df.PHQ_Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X, y, testfile='test_split_Depression_AVEC2017.csv'):\n",
    "    test_participants = pd.read_csv(testfile)['participant_ID'].values\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    \n",
    "    for i in range(y.shape[0]):\n",
    "        participant_no = y.index[i]\n",
    "        \n",
    "        if participant_no in test_participants:\n",
    "            X_test.append(X[i])\n",
    "            y_test.append(y[participant_no])\n",
    "        else:\n",
    "            X_train.append(X[i])\n",
    "            y_train.append(y[participant_no])\n",
    "    \n",
    "    return np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((136, 2902), (45, 2902), (136,), (45,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the train data in unison because data is in order\n",
    "# reduces poor performance during k-cross validation when sampling data\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=RANDOM_STATE)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics\n",
    "Some considerations in evaluation metrics when deciding our model.\n",
    "1. In our use case, it is more important to have high sensitivity as want to correctly identify as many depression cases out of all actual depression cases for early intervention. Predicting a non-depressed person as depressed is comparatively less severe, meaning we prioritize TPR (sensitivity) over FPR.\n",
    "2. Hence we will focus on `f1 score` and `recall` for the positive class.\n",
    "\n",
    "Note:\n",
    "* Sensitivity = true positive rate = recall = TP / (TP + FN)\n",
    "* Specificity = true negative rate = TN / (TN + FP)\n",
    "* Fall out = false positive rate = FP / (FP + TN)\n",
    "* Miss rate = false negative rate = FN / (FN + TP)\n",
    "\n",
    "Metrics can be found on this [website](https://scikit-learn.org/stable/modules/model_evaluation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k cross "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_cross(input_model, X=X_train, y=y_train, k=4, n=3, random_state=RANDOM_STATE):\n",
    "    f1_scores = []\n",
    "    recall_scores = []\n",
    "    rkf = RepeatedKFold(n_splits=k, n_repeats=n, random_state=RANDOM_STATE)\n",
    "        \n",
    "    for train_index, val_index in rkf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "                \n",
    "        model = clone(input_model) # prevents incremental fitting\n",
    "        model.fit(X_train, y_train) \n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "        recall = recall_score(y_val, y_pred)\n",
    "        recall_scores.append(recall)\n",
    "        \n",
    "    return f1_scores, recall_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best scores: f1 = 0.4599083869384381, recall = 0.4290445665445665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000, n_jobs=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_best_logreg_model(power):\n",
    "    best_f1_model = None\n",
    "    best_f1 = -1\n",
    "    best_recall = -1\n",
    "    \n",
    "    for i in range(power + 1):\n",
    "        model = LogisticRegression(n_jobs=3, C=10**i)\n",
    "        \n",
    "        f1_scores, recall_scores = k_cross(model)\n",
    "        f1 = np.mean(f1_scores)\n",
    "        recall = np.mean(recall_scores)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_recall = recall\n",
    "            best_f1_model = model\n",
    "    \n",
    "    print(f\"best scores: f1 = {best_f1}, recall = {best_recall}\")\n",
    "    \n",
    "    return best_f1_model\n",
    "\n",
    "find_best_logreg_model(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best scores: f1 = 0.3941575325782487, recall = 0.3691137566137566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, min_samples_leaf=18, random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_best_tree_model(upper_depth, upper_leaf):\n",
    "    best_f1_model = None\n",
    "    best_f1 = -1\n",
    "    best_recall = -1\n",
    "    \n",
    "    for depth in range(1, upper_depth + 1):\n",
    "        for leaf in range(1, upper_leaf + 1):\n",
    "            model = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=depth, min_samples_leaf=leaf) \n",
    "            \n",
    "            f1_scores, recall_scores = k_cross(model)\n",
    "            f1 = np.mean(f1_scores)\n",
    "            recall = np.mean(recall_scores)\n",
    "            \n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_recall = recall\n",
    "                best_f1_model = model\n",
    "    \n",
    "    print(f\"best scores: f1 = {best_f1}, recall = {best_recall}\")\n",
    "    \n",
    "    return best_f1_model\n",
    "\n",
    "find_best_tree_model(20, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best scores: f1 = 0.324830404772187, recall = 0.34981430606430614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1, random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_best_forest_model(n_estimators):\n",
    "    best_f1_model = None\n",
    "    best_f1 = -1\n",
    "    best_recall = -1\n",
    "    \n",
    "    for estimator in range(1, n_estimators + 1):\n",
    "        model = RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=estimator) \n",
    "        \n",
    "        f1_scores, recall_scores = k_cross(model)\n",
    "        f1 = np.mean(f1_scores)\n",
    "        recall = np.mean(recall_scores)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_recall = recall\n",
    "            best_f1_model = model\n",
    "    \n",
    "    print(f\"best scores: f1 = {best_f1}, recall = {best_recall}\")\n",
    "    \n",
    "    return best_f1_model\n",
    "\n",
    "find_best_forest_model(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done 173 out of 180 | elapsed:    4.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 128 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 173 out of 180 | elapsed:    3.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 173 out of 180 | elapsed:    4.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 173 out of 180 | elapsed:    3.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 128 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 173 out of 180 | elapsed:    4.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 173 out of 180 | elapsed:    4.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 mean score: 0.4069843717750569\n",
      "recall mean score: 0.38361314611314606\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    6.6s finished\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100]},\n",
    "                    {'kernel': ['poly'], 'degree': [3, 4, 5], 'C': [1, 10, 100]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100]}]\n",
    "\n",
    "svm_model_cv = GridSearchCV(SVC(), tuned_parameters, cv=10, scoring='f1', verbose=1, n_jobs=4)\n",
    "\n",
    "f1_scores, recall_scores = k_cross(svm_model_cv)\n",
    "\n",
    "print(f\"f1 mean score: {np.mean(f1_scores)}\")\n",
    "print(f\"recall mean score: {np.mean(recall_scores)}\")\n",
    "\n",
    "svm_model_cv.fit(X_train, y_train)\n",
    "print(svm_model_cv.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
