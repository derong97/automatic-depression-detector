{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, \\\n",
    "        f1_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"gaze_labels.csv\", index_col = \"Participant_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PHQ_Score</th>\n",
       "      <th>PHQ_Binary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PHQ_Score  PHQ_Binary\n",
       "Participant_ID                       \n",
       "300                     2           0\n",
       "301                     3           0\n",
       "302                     4           0\n",
       "303                     0           0\n",
       "304                     6           0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"avg_gaze.npy\")\n",
    "y = df['PHQ_Binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into the 4 vectors\n",
    "X_f0 = X[:,0:3]\n",
    "X_f1 = X[:,3:6]\n",
    "X_fh0 = X[:,6:9]\n",
    "X_fh1 = X[:,9:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X, y, testfile='test_split_Depression_AVEC2017.csv'):\n",
    "    test_participants = pd.read_csv(testfile)['participant_ID'].values\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    for i in range(y.shape[0]):\n",
    "        participant_no = y.index[i]\n",
    "        if participant_no in test_participants:\n",
    "            X_test.append(X[i])\n",
    "            y_test.append(y[participant_no])\n",
    "        else:\n",
    "            X_train.append(X[i])\n",
    "            y_train.append(y[participant_no])\n",
    "    return np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit the X parameter to obtain the train test sets for that feature vector\n",
    "X_train, X_test, y_train, y_test = train_test(X_fh1, y, '../test_split_Depression_AVEC2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82, 3), (45, 3), (82,), (45,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def undersampling(X_train, y_train):\n",
    "    random.seed(RANDOM_STATE)\n",
    "    \n",
    "    neg_list = [i for i in range(len(y_train)) if y_train[i] == 0]\n",
    "    pos_list = [i for i in range(len(y_train)) if y_train[i] == 1]\n",
    "    \n",
    "    if len(neg_list) < len(pos_list):\n",
    "        minority_list = neg_list\n",
    "        majority_list = pos_list\n",
    "    else:\n",
    "        minority_list = pos_list\n",
    "        majority_list = neg_list\n",
    "        \n",
    "    sampled_list = random.sample(majority_list, len(minority_list))\n",
    "    \n",
    "    final_list = sampled_list + minority_list\n",
    "    \n",
    "    X_train_us = []\n",
    "    y_train_us = []\n",
    "    \n",
    "    for i in final_list:\n",
    "        X_train_us.append(X_train[i])\n",
    "        y_train_us.append(y_train[i])\n",
    "                                 \n",
    "    return np.array(X_train_us), np.array(y_train_us)\n",
    "\n",
    "X_train, y_train = undersampling(X_train, y_train)\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=RANDOM_STATE)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"X_train_g01.npy\", X_train)\n",
    "# np.save(\"X_test_g01.npy\", X_test)\n",
    "# np.save(\"y_train_g01.npy\", y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different models using k-cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_cross(input_model, X=X_train, y=y_train, k=4, n=3, random_state=42):\n",
    "    f1_scores = []\n",
    "    recall_scores = []\n",
    "    rkf = RepeatedKFold(n_splits=k, n_repeats=n, random_state=random_state)\n",
    "    for train_index, val_index in rkf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        model = clone(input_model)\n",
    "        model.fit(X_train, y_train) \n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "        recall = recall_score(y_val, y_pred)\n",
    "        recall_scores.append(recall)\n",
    "        \n",
    "    return f1_scores, recall_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power: 0: f1 = 0.26766146688560477 > best f1 = -1\n",
      "power: 0: recall = 0.41574074074074074 > best recall = -1\n",
      "power: 1: f1 = 0.3748645068491396 > best f1 = 0.26766146688560477\n",
      "power: 1: recall = 0.4383466070966071 > best recall = 0.41574074074074074\n",
      "power: 2: f1 = 0.3844103533028807 > best f1 = 0.3748645068491396\n",
      "power: 2: recall = 0.4449673012173012 > best recall = 0.4383466070966071\n",
      "F1 score: 0.3844103533028807\n"
     ]
    }
   ],
   "source": [
    "def find_best_logreg_model(power):\n",
    "    best_f1_model = None\n",
    "    best_recall_model = None\n",
    "    best_f1 = -1\n",
    "    best_recall = -1\n",
    "    \n",
    "    for i in range(power + 1):\n",
    "        model = LogisticRegression(n_jobs=3, C=10**i)\n",
    "        \n",
    "        f1_scores, recall_scores = k_cross(model)\n",
    "        f1 = np.mean(f1_scores)\n",
    "        recall = np.mean(recall_scores)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            print(f\"power: {i}: f1 = {f1} > best f1 = {best_f1}\")\n",
    "            best_f1 = f1\n",
    "            best_f1_model = model\n",
    "\n",
    "        if recall > best_recall:\n",
    "            print(f\"power: {i}: recall = {recall} > best recall = {best_recall}\")\n",
    "            best_recall = recall\n",
    "            best_recall_model = model\n",
    "            \n",
    "    print(\"F1 score:\", best_f1)\n",
    "    \n",
    "    return best_f1_model, best_recall_model\n",
    "\n",
    "best_logreg_f1_model, best_logreg_recall_model = find_best_logreg_model(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: 1, leaf: 1: f1 = 0.32020702131866313 > best f1 = -1\n",
      "F1:  0.32020702131866313\n",
      "Recall:  0.3600281662781663\n",
      "depth: 1, leaf: 1: recall = 0.3600281662781663 > best recall = -1\n",
      "depth: 1, leaf: 5: f1 = 0.45400723265859 > best f1 = 0.32020702131866313\n",
      "F1:  0.45400723265859\n",
      "Recall:  0.500853082103082\n",
      "depth: 1, leaf: 5: recall = 0.500853082103082 > best recall = 0.3600281662781663\n",
      "depth: 1, leaf: 8: f1 = 0.48178501043636784 > best f1 = 0.45400723265859\n",
      "F1:  0.48178501043636784\n",
      "Recall:  0.5216864154364154\n",
      "depth: 1, leaf: 8: recall = 0.5216864154364154 > best recall = 0.500853082103082\n",
      "depth: 1, leaf: 10: f1 = 0.48368434566903645 > best f1 = 0.48178501043636784\n",
      "F1:  0.48368434566903645\n",
      "Recall:  0.5216864154364154\n",
      "depth: 2, leaf: 1: recall = 0.5556397306397306 > best recall = 0.5216864154364154\n",
      "depth: 2, leaf: 4: f1 = 0.5168373980998919 > best f1 = 0.48368434566903645\n",
      "F1:  0.5168373980998919\n",
      "Recall:  0.61508029008029\n",
      "depth: 2, leaf: 4: recall = 0.61508029008029 > best recall = 0.5556397306397306\n",
      "depth: 2, leaf: 11: f1 = 0.5748734022284746 > best f1 = 0.5168373980998919\n",
      "F1:  0.5748734022284746\n",
      "Recall:  0.6646059958559959\n",
      "depth: 2, leaf: 11: recall = 0.6646059958559959 > best recall = 0.61508029008029\n",
      "depth: 2, leaf: 13: f1 = 0.6203623935239176 > best f1 = 0.5748734022284746\n",
      "F1:  0.6203623935239176\n",
      "Recall:  0.7335453897953897\n",
      "depth: 2, leaf: 13: recall = 0.7335453897953897 > best recall = 0.6646059958559959\n",
      "depth: 2, leaf: 14: f1 = 0.6412061696308516 > best f1 = 0.6203623935239176\n",
      "F1:  0.6412061696308516\n",
      "Recall:  0.7647953897953897\n",
      "depth: 2, leaf: 14: recall = 0.7647953897953897 > best recall = 0.7335453897953897\n",
      "depth: 2, leaf: 16: f1 = 0.6430891931330528 > best f1 = 0.6412061696308516\n",
      "F1:  0.6430891931330528\n",
      "Recall:  0.7624271561771562\n",
      "depth: 3, leaf: 14: f1 = 0.6481506140752961 > best f1 = 0.6430891931330528\n",
      "F1:  0.6481506140752961\n",
      "Recall:  0.7776159026159027\n",
      "depth: 3, leaf: 14: recall = 0.7776159026159027 > best recall = 0.7647953897953897\n",
      "F1 score: 0.6481506140752961\n"
     ]
    }
   ],
   "source": [
    "def find_best_tree_model(upper_depth, upper_leaf):\n",
    "    best_f1_model = None\n",
    "    best_recall_model = None\n",
    "    best_f1 = -1\n",
    "    best_recall = -1\n",
    "    \n",
    "    for depth in range(1, upper_depth + 1):\n",
    "        for leaf in range(1, upper_leaf + 1):\n",
    "            model = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=depth, min_samples_leaf=leaf) \n",
    "            \n",
    "            f1_scores, recall_scores = k_cross(model)\n",
    "            f1 = np.mean(f1_scores)\n",
    "            recall = np.mean(recall_scores)\n",
    "            \n",
    "            if f1 > best_f1:\n",
    "                print(f\"depth: {depth}, leaf: {leaf}: f1 = {f1} > best f1 = {best_f1}\")\n",
    "                best_f1 = f1\n",
    "                best_f1_model = model\n",
    "                \n",
    "                print(\"F1: \",f1)\n",
    "                print(\"Recall: \", recall)\n",
    "                \n",
    "            if recall > best_recall:\n",
    "                print(f\"depth: {depth}, leaf: {leaf}: recall = {recall} > best recall = {best_recall}\")\n",
    "                best_recall = recall\n",
    "                best_recall_model = model\n",
    "                \n",
    "            \n",
    "    print(\"F1 score:\", best_f1)\n",
    "    \n",
    "    return best_f1_model, best_recall_model\n",
    "\n",
    "best_tree_f1_model, best_tree_recall_model = find_best_tree_model(20, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator: 1: f1 = 0.4114691809738249 > best f1 = -1\n",
      "estimator: 1: recall = 0.4188616938616938 > best recall = -1\n",
      "estimator: 3: f1 = 0.46462463056553777 > best f1 = 0.4114691809738249\n",
      "estimator: 3: recall = 0.47227078477078477 > best recall = 0.4188616938616938\n",
      "estimator: 5: f1 = 0.5055621601667503 > best f1 = 0.46462463056553777\n",
      "estimator: 5: recall = 0.5202845765345765 > best recall = 0.47227078477078477\n",
      "estimator: 7: f1 = 0.5175376440015018 > best f1 = 0.5055621601667503\n",
      "estimator: 7: recall = 0.5290970603470603 > best recall = 0.5202845765345765\n",
      "estimator: 9: f1 = 0.5233194345625359 > best f1 = 0.5175376440015018\n",
      "estimator: 9: recall = 0.539408508158508 > best recall = 0.5290970603470603\n",
      "F1 score: 0.5233194345625359\n"
     ]
    }
   ],
   "source": [
    "def find_best_forest_model(n_estimators):\n",
    "    best_f1_model = None\n",
    "    best_recall_model = None\n",
    "    best_f1 = -1\n",
    "    best_recall = -1\n",
    "    \n",
    "    for estimator in range(1, n_estimators + 1):\n",
    "        model = RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=estimator) \n",
    "        \n",
    "        f1_scores, recall_scores = k_cross(model)\n",
    "        f1 = np.mean(f1_scores)\n",
    "        recall = np.mean(recall_scores)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            print(f\"estimator: {estimator}: f1 = {f1} > best f1 = {best_f1}\")\n",
    "            best_f1 = f1\n",
    "            best_f1_model = model\n",
    "\n",
    "        if recall > best_recall:\n",
    "            print(f\"estimator: {estimator}: recall = {recall} > best recall = {best_recall}\")\n",
    "            best_recall = recall\n",
    "            best_recall_model = model\n",
    "    print(\"F1 score:\", best_f1)\n",
    "    \n",
    "    return best_f1_model, best_recall_model\n",
    "\n",
    "best_forest_f1_model, best_forest_recall_model = find_best_forest_model(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 235 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 235 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 235 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 220 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 235 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 220 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 235 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 235 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 235 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 235 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 235 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 235 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 mean score: 0.4746033044910453\n",
      "recall mean score: 0.6467560217560218\n",
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 235 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM parameters: {'C': 100, 'degree': 7, 'kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100]},\n",
    "                    {'kernel': ['poly'], 'degree': [3, 4, 5, 6, 7], 'C': [1, 10, 100]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000, 10000, 100000]}]\n",
    "\n",
    "svm_model_cv = GridSearchCV(SVC(), tuned_parameters, cv=10, scoring='f1', verbose=1, n_jobs=4)\n",
    "\n",
    "f1_scores, recall_scores = k_cross(svm_model_cv)\n",
    "print(f\"f1 mean score: {np.mean(f1_scores)}\")\n",
    "print(f\"recall mean score: {np.mean(recall_scores)}\")\n",
    "best_svm_model = svm_model_cv.fit(X_train, y_train)\n",
    "print(f\"Best SVM parameters: {best_svm_model.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
