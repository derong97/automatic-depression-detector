{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\65842\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\65842\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\65842\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\65842\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\65842\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\65842\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from mord import OrdinalRidge\n",
    "from mord import LAD\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_confusion_matrix(actual, predicted):\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TP = 0  \n",
    "    for i in range(len(actual)):\n",
    "        if actual[i]==0 or actual[i]==1:\n",
    "            if actual[i]==predicted[i]:\n",
    "                if actual[i]==1:\n",
    "                    TP+=1\n",
    "                elif actual[i]==0:\n",
    "                    TN+=1\n",
    "            else:\n",
    "                if predicted[i]==1:\n",
    "                    FP+=1\n",
    "                elif predicted[i]==0:\n",
    "                    FN+=1\n",
    "    \n",
    "    return TN, FP, FN, TP\n",
    "\n",
    "def eval_recall(TP, FN):\n",
    "    recall = TP/(TP+FN)\n",
    "    return recall\n",
    "\n",
    "def eval_acc(TN, FP, FN, TP):\n",
    "    acc = (TN+TP)/(TN+FP+FN+TP)\n",
    "    return acc\n",
    "\n",
    "def eval_precision(TP, FP):\n",
    "    if(TP+FP==0):\n",
    "        return 0\n",
    "    prec = TP/(TP+FP)\n",
    "    return prec\n",
    "\n",
    "def eval_f1(precision, recall):\n",
    "    if(precision+recall==0):\n",
    "        return 0\n",
    "    f1 = 2*(precision*recall)/(precision+recall)\n",
    "    return f1\n",
    "\n",
    "def evaluate(actual, predicted):\n",
    "    TN, FP, FN, TP = eval_confusion_matrix(actual, predicted)\n",
    "    recall = eval_recall(TP, FN)\n",
    "    prec = eval_precision(TP, FP)\n",
    "    f1 = eval_f1(prec, recall)\n",
    "    acc= eval_acc(TN, FP, FN, TP)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"Precision: \", prec)\n",
    "    print(\"F1 Score: \",f1)\n",
    "    print(\"Accuracy: \", acc)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = np.load(\"./text/X_train.npy\")\n",
    "X_train_a = np.load(\"./audio/X_train.npy\")\n",
    "X_test_t = np.load(\"./text/X_test.npy\")\n",
    "X_test_a = np.load(\"./audio/X_test.npy\")\n",
    "\n",
    "y_train = np.load(\"./text/y_train.npy\")\n",
    "y_test = np.load(\"./text/y_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1\n",
    "Use another logistic regression which takes in the output of these models to produce the final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to combine multiple models for transcript only\n",
    "def ensemble_models_t(models):\n",
    "    preds = []\n",
    "    for model in models:\n",
    "        y_pred = model.predict(X_train_t)\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0], 1)\n",
    "        preds.append(y_pred)\n",
    "    y_preds = np.concatenate(preds,axis=1)\n",
    "    reg = linear_model.LogisticRegression()\n",
    "    reg.fit(y_preds, y_train)\n",
    "    return reg\n",
    "\n",
    "def ensemble_prediction_t(models, reg):\n",
    "    preds = []\n",
    "    for model in models:\n",
    "        y_pred = model.predict(X_test_t)\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0], 1)\n",
    "        preds.append(y_pred)\n",
    "    y_preds = np.concatenate(preds,axis=1)\n",
    "    prediction = reg.predict(y_preds)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "# to combine 2 models (transcript and audio)\n",
    "def ensemble_models_ta(models):\n",
    "    preds = []\n",
    "    \n",
    "    y_pred = models[0].predict(X_train_t)\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], 1)\n",
    "    preds.append(y_pred)\n",
    "    y_pred = models[1].predict(X_train_a)\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], 1)\n",
    "    preds.append(y_pred)\n",
    "    \n",
    "    y_preds = np.concatenate(preds,axis=1)\n",
    "    reg = linear_model.LogisticRegression()\n",
    "    reg.fit(y_preds, y_train)\n",
    "    return reg\n",
    "\n",
    "def ensemble_prediction_ta(models, reg, X_t, X_a):\n",
    "    preds = []\n",
    "    \n",
    "    y_pred = models[0].predict(X_t)\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], 1)\n",
    "    preds.append(y_pred)\n",
    "    y_pred = models[1].predict(X_a)\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], 1)\n",
    "    preds.append(y_pred)\n",
    "    \n",
    "    y_preds = np.concatenate(preds,axis=1)\n",
    "    prediction = reg.predict(y_preds)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing using decision tree\n",
    "# Ensembling transcript and audio model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  1.0\n",
      "Precision:  0.625\n",
      "F1 Score:  0.7692307692307693\n",
      "Accuracy:  0.7272727272727273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7692307692307693"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t1 = DecisionTreeClassifier(max_depth=2, min_samples_leaf=18) \n",
    "model_t1.fit(X_train_t, y_train)\n",
    "y_pred_t1 = model_t1.predict(X_test_t)\n",
    "evaluate(y_test, y_pred_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  1.0\n",
      "Precision:  0.5555555555555556\n",
      "F1 Score:  0.7142857142857143\n",
      "Accuracy:  0.6363636363636364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a1 = DecisionTreeClassifier(max_depth=1, min_samples_leaf=1) \n",
    "model_a1.fit(X_train_a, y_train)\n",
    "y_pred_a1 = model_a1.predict(X_test_a)\n",
    "evaluate(y_test, y_pred_a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_t1, model_a1]\n",
    "reg = ensemble_models_ta(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 1 1 1 1 1 0]\n",
      "[0 0 1 1 1 0 0 0 1 1 0]\n",
      "Recall:  1.0\n",
      "Precision:  0.625\n",
      "F1 Score:  0.7692307692307693\n",
      "Accuracy:  0.7272727272727273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7692307692307693"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = ensemble_prediction_ta(models, reg, X_test_t, X_test_a)\n",
    "print(pred)\n",
    "print(y_test)\n",
    "evaluate(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with other models\n",
    "# Ensembling multiple transcript models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.6\n",
      "Precision:  1.0\n",
      "F1 Score:  0.7499999999999999\n",
      "Accuracy:  0.8181818181818182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7499999999999999"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t2 = GaussianNB()\n",
    "model_t2.fit(X_train_t, y_train)\n",
    "y_pred_t2 = model_t2.predict(X_test_t)\n",
    "evaluate(y_test, y_pred_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.8\n",
      "Precision:  0.6666666666666666\n",
      "F1 Score:  0.7272727272727272\n",
      "Accuracy:  0.7272727272727273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7272727272727272"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t3 = linear_model.LogisticRegression()\n",
    "model_t3.fit(X_train_t, y_train)\n",
    "y_pred_t3 = model_t3.predict(X_test_t)\n",
    "evaluate(y_test, y_pred_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_t1, model_t2, model_t3]\n",
    "reg = ensemble_models_t(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 0 1 0 1 1 0]\n",
      "[0 0 1 1 1 0 0 0 1 1 0]\n",
      "Recall:  0.8\n",
      "Precision:  0.6666666666666666\n",
      "F1 Score:  0.7272727272727272\n",
      "Accuracy:  0.7272727272727273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7272727272727272"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = ensemble_prediction_t(models, reg)\n",
    "print(pred)\n",
    "print(y_test)\n",
    "evaluate(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2\n",
    "Use Functional model for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "maxlen = 1000\n",
    "embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = Input(shape=(maxlen,))\n",
    "text_emb = Embedding(max_features, embedding_dim, input_length=maxlen)(text_input)\n",
    "text_layer = (Flatten())(text_emb)\n",
    "text_layer = (Dense(2))(text_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_input = Input(shape=(40,))\n",
    "audio_layer = (Dense(2))(audio_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = concatenate([text_layer, audio_layer])\n",
    "z = Dense(2, activation='softmax')(z)\n",
    "model = Model(inputs=[text_input, audio_input], outputs=[z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'model1.h5'\n",
    "es = EarlyStopping(monitor = 'val_accuracy', mode = 'max', patience = 5, min_delta=0.0001)\n",
    "checkpoint =  ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89 samples, validate on 10 samples\n",
      "Epoch 1/20\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 7.4303 - accuracy: 0.5169 - val_loss: 9.2023 - val_accuracy: 0.4000\n",
      "Epoch 2/20\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 7.4303 - accuracy: 0.5169 - val_loss: 9.2023 - val_accuracy: 0.4000\n",
      "Epoch 3/20\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 7.4303 - accuracy: 0.5169 - val_loss: 9.2023 - val_accuracy: 0.4000\n",
      "Epoch 4/20\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 7.4303 - accuracy: 0.5169 - val_loss: 9.2023 - val_accuracy: 0.4000\n",
      "Epoch 5/20\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 7.4303 - accuracy: 0.5169 - val_loss: 9.2023 - val_accuracy: 0.4000\n",
      "Epoch 6/20\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 7.4303 - accuracy: 0.5169 - val_loss: 9.2023 - val_accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_t, X_train_a], y_train, \n",
    "                    epochs=20, batch_size=4, validation_split=0.1, \n",
    "                    callbacks=[es, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 1 1 1 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([X_test_t,X_test_a])\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "print(y_pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  1.0\n",
      "Precision:  0.45454545454545453\n",
      "F1 Score:  0.625\n",
      "Accuracy:  0.45454545454545453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
