{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.6/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.6/site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.6/site-packages (from gensim) (4.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "\n",
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Processing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import random\n",
    "\n",
    "# gensim\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transcript</th>\n",
       "      <th>PHQ_Score</th>\n",
       "      <th>PHQ_Binary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>good atlanta georgia um my parents um i love i...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>thank you mmm k i good thank you i los angeles...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>i fine yourself i los angeles california part ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>okay bout yourself california yeah oh well it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>i good um los angeles california um cool weath...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Transcript  PHQ_Score  \\\n",
       "Participant_ID                                                                 \n",
       "300             good atlanta georgia um my parents um i love i...          2   \n",
       "301             thank you mmm k i good thank you i los angeles...          3   \n",
       "302             i fine yourself i los angeles california part ...          4   \n",
       "303             okay bout yourself california yeah oh well it ...          0   \n",
       "304             i good um los angeles california um cool weath...          6   \n",
       "\n",
       "                PHQ_Binary  \n",
       "Participant_ID              \n",
       "300                      0  \n",
       "301                      0  \n",
       "302                      0  \n",
       "303                      0  \n",
       "304                      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"clean_compiled_transcripts.csv\", index_col = \"Participant_ID\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained vector embeddings (skip if you have the numpy data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path('./GoogleNews-vectors-negative300.bin.gz').exists():\n",
    "    !wget -P ./ \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "CPU times: user 48 s, sys: 3.81 s, total: 51.8 s\n",
      "Wall time: 52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaging the word vectors per document\n",
    "\n",
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    # for each word in the list of words\n",
    "    for word in words:\n",
    "        # if the words are already vectors, then just append them\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        # if not: first get the vector embedding for the words\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        # error handling in case mean cannot be calculated\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        return np.zeros(wv.vector_size,)\n",
    "    \n",
    "    # use gensim's method to calculate the mean of all the words appended to mean list\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization (skip if you have the numpy data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_tokenize_text(text):\n",
    "    # create tokens, a list of words, for each post. This function will do some cleaning based on English language\n",
    "    tokens = []\n",
    "    for sent in sent_tokenize(text, language='english'):\n",
    "        for word in word_tokenize(sent, language='english'):\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df.apply(lambda r: w2v_tokenize_text(r['Transcript']), axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset (skip if you have the numpy data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "X = word_averaging_list(wv, tokenized)\n",
    "y = df.PHQ_Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X, y, testfile='test_split_Depression_AVEC2017.csv'):\n",
    "    test_participants = pd.read_csv(testfile)['participant_ID'].values\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    \n",
    "    for i in range(y.shape[0]):\n",
    "        participant_no = y.index[i]\n",
    "        \n",
    "        if participant_no in test_participants:\n",
    "            X_test.append(X[i])\n",
    "            y_test.append(y[participant_no])\n",
    "        else:\n",
    "            X_train.append(X[i])\n",
    "            y_train.append(y[participant_no])\n",
    "    \n",
    "    return np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "# because the RandomUnderSampler does not work here\n",
    "def undersampling(X_train, y_train):\n",
    "    random.seed(RANDOM_STATE)\n",
    "    \n",
    "    neg_list = [i for i in range(len(y_train)) if y_train[i] == 0]\n",
    "    pos_list = [i for i in range(len(y_train)) if y_train[i] == 1]\n",
    "    \n",
    "    if len(neg_list) < len(pos_list):\n",
    "        minority_list = neg_list\n",
    "        majority_list = pos_list\n",
    "    else:\n",
    "        minority_list = pos_list\n",
    "        majority_list = neg_list\n",
    "        \n",
    "    sampled_list = random.sample(majority_list, len(minority_list))\n",
    "    \n",
    "    final_list = sampled_list + minority_list\n",
    "    \n",
    "    X_train_us = []\n",
    "    y_train_us = []\n",
    "    \n",
    "    for i in final_list:\n",
    "        X_train_us.append(X_train[i])\n",
    "        y_train_us.append(y_train[i])\n",
    "                                 \n",
    "    return np.array(X_train_us), np.array(y_train_us)\n",
    "\n",
    "X_train, y_train = undersampling(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82, 300), (45, 300), (82,), (45,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the train data in unison because data is in order\n",
    "# reduces poor performance during k-cross validation when sampling data\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=RANDOM_STATE)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_train_mean_w2v.npy\", X_train)\n",
    "np.save(\"X_test_mean_w2v.npy\", X_test)\n",
    "np.save(\"y_train_mean_w2v.npy\", y_train)\n",
    "np.save(\"y_test_mean_w2v.npy\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"X_train_mean_w2v.npy\")\n",
    "X_test = np.load(\"X_test_mean_w2v.npy\")\n",
    "y_train = np.load(\"y_train_mean_w2v.npy\")\n",
    "y_test = np.load(\"y_test_mean_w2v.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics\n",
    "Some considerations in evaluation metrics when deciding our model.\n",
    "1. In our use case, it is more important to have high sensitivity as want to correctly identify as many depression cases out of all actual depression cases for early intervention. Predicting a non-depressed person as depressed is comparatively less severe, meaning we prioritize TPR (sensitivity) over FPR.\n",
    "2. Hence we will focus on `f1 score` and `recall` for the positive class.\n",
    "\n",
    "Note:\n",
    "* Sensitivity = true positive rate = recall = TP / (TP + FN)\n",
    "* Specificity = true negative rate = TN / (TN + FP)\n",
    "* Fall out = false positive rate = FP / (FP + TN)\n",
    "* Miss rate = false negative rate = FN / (FN + TP)\n",
    "\n",
    "Metrics can be found on this [website](https://scikit-learn.org/stable/modules/model_evaluation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k cross "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_cross(input_model, X=X_train, y=y_train, k=4, n=3, random_state=RANDOM_STATE):\n",
    "    f1_scores = []\n",
    "    recall_scores = []\n",
    "    rkf = RepeatedKFold(n_splits=k, n_repeats=n, random_state=RANDOM_STATE)\n",
    "        \n",
    "    for train_index, val_index in rkf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "                \n",
    "        model = clone(input_model) # prevents incremental fitting\n",
    "        model.fit(X_train, y_train) \n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "        recall = recall_score(y_val, y_pred)\n",
    "        recall_scores.append(recall)\n",
    "        \n",
    "    return f1_scores, recall_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best scores: f1 = 0.6224613028869995, recall = 0.657337801087801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, n_jobs=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_best_logreg_model(power):\n",
    "    best_f1_model = None\n",
    "    best_f1 = -1\n",
    "    best_recall = -1\n",
    "    \n",
    "    for i in range(power + 1):\n",
    "        model = LogisticRegression(n_jobs=3, C=10**i)\n",
    "        \n",
    "        f1_scores, recall_scores = k_cross(model)\n",
    "        f1 = np.mean(f1_scores)\n",
    "        recall = np.mean(recall_scores)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_recall = recall\n",
    "            best_f1_model = model\n",
    "    \n",
    "    print(f\"best scores: f1 = {best_f1}, recall = {best_recall}\")\n",
    "    \n",
    "    return best_f1_model\n",
    "\n",
    "find_best_logreg_model(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best scores: f1 = 0.6538356088356089, recall = 0.7946289821289821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=1, random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_best_tree_model(upper_depth, upper_leaf):\n",
    "    best_f1_model = None\n",
    "    best_f1 = -1\n",
    "    best_recall = -1\n",
    "    \n",
    "    for depth in range(1, upper_depth + 1):\n",
    "        for leaf in range(1, upper_leaf + 1):\n",
    "            model = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=depth, min_samples_leaf=leaf) \n",
    "            \n",
    "            f1_scores, recall_scores = k_cross(model)\n",
    "            f1 = np.mean(f1_scores)\n",
    "            recall = np.mean(recall_scores)\n",
    "            \n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_recall = recall\n",
    "                best_f1_model = model\n",
    "    \n",
    "    print(f\"best scores: f1 = {best_f1}, recall = {best_recall}\")\n",
    "    \n",
    "    return best_f1_model\n",
    "\n",
    "find_best_tree_model(20, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best scores: f1 = 0.5773372826004406, recall = 0.6226916601916602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=17, random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_best_forest_model(n_estimators):\n",
    "    best_f1_model = None\n",
    "    best_f1 = -1\n",
    "    best_recall = -1\n",
    "    \n",
    "    for estimator in range(1, n_estimators + 1):\n",
    "        model = RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=estimator) \n",
    "        \n",
    "        f1_scores, recall_scores = k_cross(model)\n",
    "        f1 = np.mean(f1_scores)\n",
    "        recall = np.mean(recall_scores)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_recall = recall\n",
    "            best_f1_model = model\n",
    "    \n",
    "    print(f\"best scores: f1 = {best_f1}, recall = {best_recall}\")\n",
    "    \n",
    "    return best_f1_model\n",
    "\n",
    "find_best_forest_model(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 123 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 mean score: 0.6040700891275604\n",
      "recall mean score: 0.6994172494172494\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "{'C': 10, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100]},\n",
    "                    {'kernel': ['poly'], 'degree': [3, 4, 5], 'C': [1, 10, 100]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100]}]\n",
    "\n",
    "svm_model_cv = GridSearchCV(SVC(), tuned_parameters, cv=10, scoring='f1', verbose=1, n_jobs=4)\n",
    "\n",
    "f1_scores, recall_scores = k_cross(svm_model_cv)\n",
    "\n",
    "print(f\"f1 mean score: {np.mean(f1_scores)}\")\n",
    "print(f\"recall mean score: {np.mean(recall_scores)}\")\n",
    "\n",
    "svm_model_cv.fit(X_train, y_train)\n",
    "print(svm_model_cv.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
