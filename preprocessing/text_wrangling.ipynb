{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "excluded_pronouns = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
    "                    \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
    "                     'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves']\n",
    "\n",
    "for pronoun in excluded_pronouns:\n",
    "    stop_words.remove(pronoun)\n",
    "\n",
    "state_names = [\"Alaska\", \"Alabama\", \"Arkansas\", \"American Samoa\", \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \n",
    "               \"Columbia\", \"Delaware\", \"Florida\", \"Georgia\", \"Guam\", \"Hawaii\", \"Iowa\", \"Idaho\", \"Illinois\", \"Indiana\", \n",
    "               \"Kansas\", \"Kentucky\", \"Louisiana\", \"Los Angeles\", \"Massachusetts\", \"Maryland\", \"Maine\", \"Michigan\", \n",
    "               \"Minnesota\", \"Missouri\", \"Mississippi\", \"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \n",
    "               \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \n",
    "               \"Pennsylvania\", \"Puerto Rico\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \n",
    "               \"Utah\", \"Virginia\", \"Virgin Islands\", \"Vermont\", \"Washington\", \"Wisconsin\", \"West Virginia\", \"Wyoming\"]\n",
    "\n",
    "state_names = [i.lower() for i in state_names]\n",
    "\n",
    "blacklist = state_names + stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /opt/conda/lib/python3.6/site-packages (0.0.25)\r\n",
      "Requirement already satisfied: textsearch in /opt/conda/lib/python3.6/site-packages (from contractions) (0.0.17)\r\n",
      "Requirement already satisfied: pyahocorasick in /opt/conda/lib/python3.6/site-packages (from textsearch->contractions) (1.4.0)\r\n",
      "Requirement already satisfied: Unidecode in /opt/conda/lib/python3.6/site-packages (from textsearch->contractions) (1.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import contractions\n",
    "import re as re\n",
    "import string\n",
    "\n",
    "def filter_text(text):\n",
    "    \n",
    "    text = re.sub('<[^<]+?>', '', text) # remove anything enclosed by tags e.g. <>\n",
    "    text = re.sub('\\[(.*?)\\]', '', text) # remove anything enclosed by closed brackets i.e. []\n",
    "    text = contractions.fix(text) # expands contractions e.g.'he's happy' -> 'he is happy'\n",
    "    \n",
    "    text = text.lower() # contractions will capitalize 'i'\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation)) # remove remaining punctuations e.g. apostrophe\n",
    "    \n",
    "    tokens = TweetTokenizer().tokenize(text) # use TweetTokenizer as transcripts contain informal texts\n",
    "    filtered_sentence = [w for w in tokens if w not in blacklist]\n",
    "    text = ' '.join(filtered_sentence)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare text filtering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/raw_compiled_transcripts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original text is:\n",
      "good atlanta georgia um my parents are from here um i love it i like the weather i like the opportunities um yes um it took a minute somewhat easy congestion that's it um i took up business and administration uh yeah i am here and there i'm on a break right now but i plan on going back in the uh next semester uh probably to open up my own business no um no specific reason i just don't travel a lot i'm pretty local once a year can you be a little bit more specific no answer i like reading books i enjoy i enjoy cooking um exercising is great i'm i'm i'm pretty good at it um yeah um probably about two weeks ago uh frustrated um i don't like bias um i don't like um when someone says they're gonna do something and they don't uh somewhat friendship i like to play sports i enjoy uh going out with friends and family playing games grandparents parents um yeah i mean they've always given me great advice they've always kept it real real close i would say going to college right after high school well i would've been done by now you know i would have been probably out in the field in the career field uh taking a job off the street i'm sure i could've yes i'm not sure maybe when i graduated from high school well uh i um i got my diploma my my diploma that i finished school and i met all the requirements  high school and i was approved to go do whatever i wanted to do living with who um it's alright it could be better not no uh it's pretty easy uh yes repeat that irritated um lazy no no no no um the other day weather was great sun was out different less less um interested uh shut down uh about two weeks ago uh yeah a friend of mine was annoying me and i just cut them off [laughter] it's alright friendship chocolate tall thin thank you bye bye\n",
      "-------------------------------------------\n",
      "The filtered text is:\n",
      "good atlanta um my parents um i love it i like weather i like opportunities um yes um it took minute somewhat easy congestion it um i took business administration uh yeah i i break right i plan going back uh next semester uh probably open my business um specific reason i travel lot i pretty local year you little bit specific answer i like reading books i enjoy i enjoy cooking um exercising great i i i pretty good it um yeah um probably two weeks ago uh frustrated um i like bias um i like um someone says they going something they uh somewhat friendship i like play sports i enjoy uh going friends family playing games grandparents parents um yeah i mean they always given me great advice they always kept it real real close i would say going college right high school well i would done you know i would probably field career field uh taking job street i sure i could yes i sure maybe i graduated high school well uh i um i got my diploma my my diploma i finished school i met requirements high school i approved go whatever i wanted living um it alright it could better uh it pretty easy uh yes repeat irritated um lazy um day weather great sun different less less um interested uh shut uh two weeks ago uh yeah friend mine annoying me i cut them it alright friendship chocolate tall thin thank you bye bye\n"
     ]
    }
   ],
   "source": [
    "# Compare first entry\n",
    "\n",
    "original_text = df.Transcript[0]\n",
    "\n",
    "df.Transcript = df.Transcript.apply(filter_text)\n",
    "filtered_text = df.Transcript[0]\n",
    "\n",
    "print(f\"The original text is:\\n{original_text}\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(f\"The filtered text is:\\n{filtered_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results in a new global dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>PHQ_Score</th>\n",
       "      <th>PHQ_Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>good atlanta um my parents um i love it i like...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>thank you mmm k i good thank you i los angeles...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "      <td>i fine yourself i los angeles part okay um my ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303</td>\n",
       "      <td>okay bout yourself yeah oh well it big broad l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304</td>\n",
       "      <td>i good um los angeles um cool weather beaches ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant_ID                                         Transcript  \\\n",
       "0             300  good atlanta um my parents um i love it i like...   \n",
       "1             301  thank you mmm k i good thank you i los angeles...   \n",
       "2             302  i fine yourself i los angeles part okay um my ...   \n",
       "3             303  okay bout yourself yeah oh well it big broad l...   \n",
       "4             304  i good um los angeles um cool weather beaches ...   \n",
       "\n",
       "   PHQ_Score  PHQ_Binary  \n",
       "0          2           0  \n",
       "1          3           0  \n",
       "2          4           0  \n",
       "3          0           0  \n",
       "4          6           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"../data/clean_compiled_transcripts.csv\", index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
