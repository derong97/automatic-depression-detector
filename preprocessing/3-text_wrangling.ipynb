{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Using cached contractions-0.0.25-py2.py3-none-any.whl (3.2 kB)\n",
      "Collecting textsearch\n",
      "  Using cached textsearch-0.0.17-py2.py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: Unidecode in /opt/conda/lib/python3.6/site-packages (from textsearch->contractions) (1.1.1)\n",
      "Processing /home/jovyan/.cache/pip/wheels/16/ec/84/27daa7f8d8c0bdad46f462e2834faa13cfda30ea07097e0e3d/pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl\n",
      "Installing collected packages: pyahocorasick, textsearch, contractions\n",
      "Successfully installed contractions-0.0.25 pyahocorasick-1.4.0 textsearch-0.0.17\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "# depressed persons tend to use first-person pronouns more, and third-person pronouns less. these words might provide indication\n",
    "excluded_pronouns = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
    "                    \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
    "                     'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves']\n",
    "\n",
    "for pronoun in excluded_pronouns:\n",
    "    stop_words.remove(pronoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "import contractions\n",
    "import re as re\n",
    "import string\n",
    "\n",
    "def filter_text(text):\n",
    "    \n",
    "    text = re.sub('<[^<]+?>', '', text) # remove anything enclosed by tags e.g. <>\n",
    "    text = re.sub('\\[(.*?)\\]', '', text) # remove anything enclosed by closed brackets i.e. []\n",
    "    text = contractions.fix(text) # expands contractions e.g.'he's happy' -> 'he is happy'\n",
    "    \n",
    "    text = text.lower() # contractions will capitalize 'i'\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation)) # remove remaining punctuations e.g. apostrophe\n",
    "    \n",
    "    tokens = TweetTokenizer().tokenize(text) # use TweetTokenizer as transcripts contain informal texts\n",
    "    \n",
    "    filtered_sentence = [w for w in tokens if w not in stop_words]\n",
    "    text = ' '.join(filtered_sentence)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare text filtering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"raw_compiled_transcripts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original text is:\n",
      "good atlanta georgia um my parents are from here um i love it i like the weather i like the opportunities um yes um it took a minute somewhat easy congestion that's it um i took up business and administration uh yeah i am here and there i'm on a break right now but i plan on going back in the uh next semester uh probably to open up my own business no um no specific reason i just don't travel a lot i'm pretty local once a year can you be a little bit more specific no answer i like reading books i enjoy i enjoy cooking um exercising is great i'm i'm i'm pretty good at it um yeah um probably about two weeks ago uh frustrated um i don't like bias um i don't like um when someone says they're gonna do something and they don't uh somewhat friendship i like to play sports i enjoy uh going out with friends and family playing games grandparents parents um yeah i mean they've always given me great advice they've always kept it real real close i would say going to college right after high school well i would've been done by now you know i would have been probably out in the field in the career field uh taking a job off the street i'm sure i could've yes i'm not sure maybe when i graduated from high school well uh i um i got my diploma my my diploma that i finished school and i met all the requirements  high school and i was approved to go do whatever i wanted to do living with who um it's alright it could be better not no uh it's pretty easy uh yes repeat that irritated um lazy no no no no um the other day weather was great sun was out different less less um interested uh shut down uh about two weeks ago uh yeah a friend of mine was annoying me and i just cut them off [laughter] it's alright friendship chocolate tall thin thank you bye bye\n",
      "-------------------------------------------\n",
      "The filtered text is:\n",
      "good atlanta georgia um my parents um i love it i like weather i like opportunities um yes um it took minute somewhat easy congestion it um i took business administration uh yeah i i break right i plan going back uh next semester uh probably open my business um specific reason i travel lot i pretty local year you little bit specific answer i like reading books i enjoy i enjoy cooking um exercising great i i i pretty good it um yeah um probably two weeks ago uh frustrated um i like bias um i like um someone says they going something they uh somewhat friendship i like play sports i enjoy uh going friends family playing games grandparents parents um yeah i mean they always given me great advice they always kept it real real close i would say going college right high school well i would done you know i would probably field career field uh taking job street i sure i could yes i sure maybe i graduated high school well uh i um i got my diploma my my diploma i finished school i met requirements high school i approved go whatever i wanted living um it alright it could better uh it pretty easy uh yes repeat irritated um lazy um day weather great sun different less less um interested uh shut uh two weeks ago uh yeah friend mine annoying me i cut them it alright friendship chocolate tall thin thank you bye bye\n"
     ]
    }
   ],
   "source": [
    "# Compare first entry\n",
    "\n",
    "original_text = df.Transcript[0]\n",
    "\n",
    "df.Transcript = df.Transcript.apply(filter_text)\n",
    "filtered_text = df.Transcript[0]\n",
    "\n",
    "print(f\"The original text is:\\n{original_text}\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(f\"The filtered text is:\\n{filtered_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results in a new global dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>PHQ_Score</th>\n",
       "      <th>PHQ_Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>good atlanta georgia um my parents um i love i...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>thank you mmm k i good thank you i los angeles...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "      <td>i fine yourself i los angeles california part ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303</td>\n",
       "      <td>okay bout yourself california yeah oh well it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304</td>\n",
       "      <td>i good um los angeles california um cool weath...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant_ID                                         Transcript  \\\n",
       "0             300  good atlanta georgia um my parents um i love i...   \n",
       "1             301  thank you mmm k i good thank you i los angeles...   \n",
       "2             302  i fine yourself i los angeles california part ...   \n",
       "3             303  okay bout yourself california yeah oh well it ...   \n",
       "4             304  i good um los angeles california um cool weath...   \n",
       "\n",
       "   PHQ_Score  PHQ_Binary  \n",
       "0          2           0  \n",
       "1          3           0  \n",
       "2          4           0  \n",
       "3          0           0  \n",
       "4          6           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"clean_compiled_transcripts.csv\", index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
